{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Pre-Process"
      ],
      "metadata": {
        "id": "4y3BVcmahtlc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wWizZTAhoFy"
      },
      "outputs": [],
      "source": [
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def levenshtein_similarity(str1, str2):\n",
        "    distance = Levenshtein.distance(str1, str2)\n",
        "    max_len = max(len(str1), len(str2))\n",
        "    return (1 - distance / max_len) * 100\n",
        "\n",
        "def filter_questions(csv_file_path, output_csv_file_path, question_col='Questions'):\n",
        "    try:\n",
        "        print(\"Reading the CSV file.\")\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "\n",
        "        if question_col not in df.columns:\n",
        "            raise ValueError(f\"Column '{question_col}' not found in the CSV file.\")\n",
        "\n",
        "        print(\"Processing questions for full stop and length filtering.\")\n",
        "        df[question_col] = df[question_col].str.replace(r'\\.\\?', '?', regex=True)\n",
        "        df = df[df[question_col].str.len() <= 300]\n",
        "\n",
        "        # Removing questions with 80% similarity or above using levenshtein distance\n",
        "        print(\"Starting Levenshtein similarity check.\")\n",
        "        to_remove = set()\n",
        "        num_questions = len(df)\n",
        "        for i in range(num_questions):\n",
        "            for j in range(i + 1, num_questions):\n",
        "                if levenshtein_similarity(df.iloc[i][question_col], df.iloc[j][question_col]) >= 80:\n",
        "                    to_remove.add(j)\n",
        "            print(f\"Processed question {i + 1}/{num_questions}\")\n",
        "\n",
        "        filtered_df = df.drop(df.index[list(to_remove)])\n",
        "\n",
        "        print(\"Saving the filtered data to a new CSV file.\")\n",
        "        filtered_df.to_csv(output_csv_file_path, index=False)\n",
        "        print(f\"Filtered data saved to {output_csv_file_path}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {csv_file_path} was not found.\")\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"Error: No data found in the file {csv_file_path}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "input_csv = 'Irrelevant Questions.csv'\n",
        "output_csv = 'Filtered_Irrelevant_Questions.csv'\n",
        "filter_questions(input_csv, output_csv)"
      ],
      "metadata": {
        "id": "CVzI7BKvhvsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bloom's Taxonomy Keywords"
      ],
      "metadata": {
        "id": "6bgByh0Fh6iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Knowledge (Remember)\n",
        "\n",
        "bloom_knowledge = [\n",
        "    'choose', 'chooses', 'chosen', 'choosing', 'chose'\n",
        "    'define', 'defines', 'defined', 'defining',\n",
        "    'find', 'finds', 'found', 'finding',\n",
        "    'how', \"how's\",\n",
        "    'label', 'labels', 'labeled', 'labeling',\n",
        "    'list', 'lists', 'listed', 'listing',\n",
        "    'match', 'matches', 'matched', 'matching',\n",
        "    'name', 'names', 'named', 'naming',\n",
        "    'omit', 'omits', 'omited', 'omiting',\n",
        "    'recall', 'recalls', 'recalled', 'recalling',\n",
        "    'spell', 'spells', 'spelled', 'spelling',\n",
        "    'tell', 'tells', 'told', 'telling',\n",
        "    'what', \"what's\",\n",
        "    'when', \"when's\",\n",
        "    'where', \"where's\",\n",
        "    'which', \"which's\",\n",
        "    'who', \"who's\",\n",
        "    'why', \"why's\",\n",
        "\t\t'underline', 'underlined', 'underlining', 'underlines'\n",
        "\t\t'tally', 'tallying', 'tallyed', 'tallied', 'tallies'\n",
        "\t\t'trace', 'traced', 'tracing', 'traces',\n",
        "\t\t'bookmark', 'bookmarked', 'bookmarking', 'bookmarks',\n",
        "    'bullet-point', 'bullet-pointed', 'bullet-pointing', 'bullet-points',\n",
        "    'cite', 'cited', 'cites', 'citing',\n",
        "    'copy', 'copies', 'copied', 'copying',\n",
        "    'duplicate', 'duplicates', 'duplicated', 'duplicating',\n",
        "    'enumerate', 'enumerates', 'enumerated', 'enumerating',\n",
        "    'google', 'googles', 'googled', 'googling',\n",
        "    'highlight', 'highlights', 'highlighted', 'highlighting',\n",
        "    'identify', 'identifies', 'identified', 'identifying',\n",
        "    'index', 'indexes', 'indexed', 'indexing',\n",
        "    'indicate', 'indicates', 'indicated', 'indicating',\n",
        "    'listen', 'listens', 'listened', 'listening',\n",
        "    'locate', 'locates', 'located', 'locating',\n",
        "    'meet', 'meets', 'meeted', 'meeting',\n",
        "    'memorize', 'memorizes', 'memorized', 'memorizing',\n",
        "    'point', 'points', 'pointed', 'pointing',\n",
        "    'quote', 'quotes', 'quoted', 'quoting',\n",
        "    'read', 'reads', 'readed', 'reading',\n",
        "    'recite', 'recites', 'recited', 'reciting',\n",
        "    'recognize', 'recognizes', 'recognized', 'recognizing',\n",
        "    'record', 'records', 'recorded', 'recording',\n",
        "    'repeat', 'repeats', 'repeated', 'repeating',\n",
        "    'reproduce', 'reproduces', 'reproduced', 'reproducing',\n",
        "    'retrieve', 'retrieves', 'retrieved', 'retrieving',\n",
        "    'review', 'reviews', 'reviewed', 'reviewing',\n",
        "    'search', 'searchs', 'searched', 'searching',\n",
        "    'state', 'states', 'stated', 'stating',\n",
        "    'study', 'studys', 'studyed', 'studying',\n",
        "]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nqPtZAqIh8n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Comprehension (Understand)\n",
        "\n",
        "bloom_understand = [\n",
        "    'acquire', 'acquired', 'acquires', 'acquiring',\n",
        "    'add', 'added', 'adding', 'adds',\n",
        "    'annotate', 'annotated', 'annotates', 'annotating',\n",
        "    'approximate', 'approximated', 'approximates', 'approximating', 'approximately'\n",
        "    'associate', 'associated', 'associates', 'associating',\n",
        "    'clarify', 'clarifies', 'clarified', 'clarifying',\n",
        "    'convert', 'converted', 'converting', 'converts',\n",
        "    'describe', 'described', 'describes', 'describing',\n",
        "    'detail', 'detailed', 'detailing', 'details',\n",
        "    'example', 'examples', 'exampled', 'exampling',\n",
        "    'exemplify', 'exemplifys', 'exemplified', 'exemplifying',\n",
        "    'explain', 'explained', 'explaining', 'explains',\n",
        "    'extend', 'extended', 'extending', 'extends',\n",
        "    'extrapolate', 'extrapolated', 'extrapolates', 'extrapolating',\n",
        "    'gather', 'gathered', 'gathering', 'gathers',\n",
        "    'give', 'gives', 'gave', 'giving', 'given',\n",
        "    'give example', 'give examples', 'gave example', 'gave examples', 'giving example', 'giving examples',\n",
        "    'interact', 'interacted', 'interacting', 'interacts',\n",
        "    'journal', 'journals', 'journaled', 'journaling',\n",
        "    'link', 'linked', 'links', 'linking',\n",
        "    'observe', 'observed', 'observes', 'observing',\n",
        "    'outline', 'outlined', 'outlines', 'outlining',\n",
        "    'paraphrase', 'paraphrased', 'paraphrases', 'paraphrasing',\n",
        "    'picture graphically', 'pictures graphically', 'pictured graphically', 'picturing graphically',\n",
        "\t\t'pictures', 'pictured', 'picturing',\n",
        "    'relate', 'related', 'relates', 'relating',\n",
        "    'rephrase', 'rephrased', 'rephrases', 'rephrasing',\n",
        "    'subtract', 'subtracted', 'subtracting', 'subtracts',\n",
        "    'summarize', 'summarized', 'summarizes', 'summarizing',\n",
        "    'tag', 'tags', 'tagged', 'tagging',\n",
        "    'tweet', 'tweets', 'tweeted', 'tweeting',\n",
        "    'visualize', 'visualized', 'visualizes', 'visualizing'\n",
        "]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0_Uc0Stdh9Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Application (Applying)\n",
        "\n",
        "bloom_application = [\n",
        "    'act out', 'acts out', 'acted out', 'acting out',\n",
        "    'allocate', 'allocates', 'allocated', 'allocating',\n",
        "    'alphabetize', 'alphabetizes', 'alphabetized', 'alphabetizing',\n",
        "    'amend', 'amends', 'amended', 'amending',\n",
        "    'apply', 'applys', 'applyed', 'applying',\n",
        "    'articulate', 'articulates', 'articulated', 'articulating',\n",
        "    'ascertain', 'ascertains', 'ascertained', 'ascertaining',\n",
        "    'assign', 'assigns', 'assigned', 'assigning',\n",
        "    'attain', 'attains', 'attained', 'attaining',\n",
        "    'avoid', 'avoids', 'avoided', 'avoiding',\n",
        "    'back', 'backs', 'backed', 'backing',\n",
        "    'back up', 'backs up', 'backed up', 'backing up',\n",
        "    'calculate', 'calculates', 'calculated', 'calculating',\n",
        "    'capture', 'captures', 'captured', 'capturing',\n",
        "    'change', 'changes', 'changed', 'changing',\n",
        "    'chart', 'charts', 'charted', 'charting',\n",
        "    'compute', 'computes', 'computed', 'computing',\n",
        "    'concatenate', 'concatenates', 'concatenated', 'concatenating',\n",
        "    'conduct', 'conducts', 'conducted', 'conducting',\n",
        "    'consult', 'consults', 'consulted', 'consulting',\n",
        "    'convey', 'conveys', 'conveyed', 'conveying',\n",
        "    'coordinate', 'coordinates', 'coordinated', 'coordinating',\n",
        "    'customize', 'customizes', 'customized', 'customizing',\n",
        "    'deliver', 'delivers', 'delivered', 'delivering',\n",
        "    'demonstrate', 'demonstrates', 'demonstrated', 'demonstrating',\n",
        "    'depreciate', 'depreciates', 'depreciated', 'depreciating',\n",
        "    'derive', 'derives', 'derived', 'deriving',\n",
        "    'determine', 'determines', 'determined', 'determining',\n",
        "    'diminish', 'diminishs', 'diminished', 'diminishing',\n",
        "    'discover', 'discovers', 'discovered', 'discovering',\n",
        "    'display', 'displays', 'displayed', 'displaying',\n",
        "    'divide', 'divides', 'divided', 'dividing',\n",
        "    'dramatize', 'dramatizes', 'dramatized', 'dramatizing',\n",
        "    'draw', 'draws', 'drawed', 'drawing',\n",
        "    'employ', 'employs', 'employed', 'employing',\n",
        "    'engineer', 'engineers', 'engineered', 'engineering',\n",
        "\t\t'estimate', 'estimated', 'estimates', 'estimating',\n",
        "    'examine', 'examines', 'examined', 'examining',\n",
        "    'execute', 'executes', 'executed', 'executing',\n",
        "    'exercise', 'exercises', 'exercised', 'exercising',\n",
        "    'expand', 'expands', 'expanded', 'expanding',\n",
        "    'experiment', 'experiments', 'experimented', 'experimenting',\n",
        "    'experiment with', 'experiments with', 'experimented with', 'experimenting with',\n",
        "    'expose', 'exposes', 'exposed', 'exposing',\n",
        "    'express', 'expresss', 'expressed', 'expressing',\n",
        "    'figure', 'figures', 'figured', 'figuring',\n",
        "    'graph', 'graphs', 'graphed', 'graphing',\n",
        "    'guide', 'guides', 'guided', 'guiding',\n",
        "    'hack', 'hacks', 'hacked', 'hacking',\n",
        "    'handle', 'handles', 'handled', 'handling',\n",
        "    'illustrate', 'illustrates', 'illustrated', 'illustrating',\n",
        "    'implement', 'implements', 'implemented', 'implementing',\n",
        "    'interconvert', 'interconverts', 'interconverted', 'interconverting',\n",
        "    'interview', 'interviews', 'interviewed', 'interviewing',\n",
        "    'load', 'loads', 'loaded', 'loading',\n",
        "    'make use of', 'makes use of', 'made use of', 'making use of',\n",
        "\t\t'manage', 'managed', 'managing', 'manages',\n",
        "    'manipulate', 'manipulates', 'manipulated', 'manipulating',\n",
        "    'modify', 'modifies', 'modified', 'modifying',\n",
        "    'multiply', 'multiplies', 'multiplied', 'multiplying',\n",
        "    'obtain', 'obtains', 'obtained', 'obtaining',\n",
        "    'operate', 'operates', 'operated', 'operating',\n",
        "    'paint', 'paints', 'painted', 'painting',\n",
        "    'perform', 'performs', 'performed', 'performing',\n",
        "    'personalize', 'personalizes', 'personalized', 'personalizing',\n",
        "    'play', 'plays', 'played', 'playing',\n",
        "    'plot', 'plots', 'plotted', 'plotting',\n",
        "    'practice', 'practices', 'practiced', 'practicing',\n",
        "    'prepare', 'prepares', 'prepared', 'preparing',\n",
        "    'present', 'presents', 'presented', 'presenting',\n",
        "    'price', 'prices', 'priced', 'pricing',\n",
        "    'process', 'processs', 'processed', 'processing',\n",
        "    'project', 'projects', 'projected', 'projecting',\n",
        "    'protect', 'protects', 'protected', 'protecting',\n",
        "    'provide', 'provides', 'provided', 'providing',\n",
        "    'reenact', 'reenacts', 'reenacted', 'reenacting',\n",
        "    'round off', 'rounds off', 'rounded off', 'rounding off',\n",
        "    'sequence', 'sequences', 'sequenced', 'sequencing',\n",
        "    'show', 'shows', 'showed', 'showing', 'shown',\n",
        "    'simplify', 'simplifies', 'simplifyed', 'simplifying',\n",
        "    'simulate', 'simulates', 'simulated', 'simulating',\n",
        "    'sketch', 'sketches', 'sketched', 'sketching',\n",
        "    'solve', 'solves', 'solved', 'solving',\n",
        "    'subscribe', 'subscribes', 'subscribed', 'subscribing',\n",
        "\t\t'unsubscribe', 'unsubscribes', 'unsubscribed', 'unsubscribing',\n",
        "    'tabulate', 'tabulates', 'tabulated', 'tabulating',\n",
        "    'transcribe', 'transcribes', 'transcribed', 'transcribing',\n",
        "    'translate', 'translates', 'translated', 'translating',\n",
        "    'use', 'uses', 'used', 'using',\n",
        "    'utilize', 'utilizes', 'utilized', 'utilizing'\n",
        "]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nWaqL5-3iBQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Analysis (Analytical)\n",
        "\n",
        "bloom_analysis = [\n",
        "    'accept', 'accepted', 'accepting', 'accepts',\n",
        "    'administer', 'administered', 'administering', 'administers',\n",
        "    'advertise', 'advertised', 'advertises', 'advertising',\n",
        "    'allow', 'allowed', 'allowing', 'allows',\n",
        "    'analyze', 'analyzed', 'analyzes', 'analyzing',\n",
        "    'attribute', 'attributed', 'attributes', 'attributing',\n",
        "    'audit', 'audited', 'auditing', 'audits',\n",
        "    'blueprint', 'blueprinted', 'blueprinting', 'blueprints',\n",
        "    'breadboard', 'breadboarded', 'breadboarding', 'breadboards',\n",
        "    'break down', 'breaks down', 'broken down', 'breaking down',\n",
        "    'categorize', 'categorized', 'categorizes', 'categorizing',\n",
        "    'characterize', 'characterized', 'characterizes', 'characterizing',\n",
        "    'check', 'checked', 'checking', 'checks',\n",
        "    'chunk', 'chunked', 'chunking', 'chunks',\n",
        "    'classify', 'classified', 'classifying', 'classifys',\n",
        "    'compare', 'compared', 'compares', 'comparing',\n",
        "    'confirm', 'confirmed', 'confirming', 'confirms',\n",
        "\t\t'consolidate', 'consolidated', 'consolidates', 'consolidating',\n",
        "    'contrast', 'contrasted', 'contrasting', 'contrasts',\n",
        "    'correlate', 'correlated', 'correlating', 'correlates',\n",
        "    'corroborate', 'corroborated', 'corroborates', 'corroborating',\n",
        "    'deconstruct', 'deconstructed', 'deconstructing', 'deconstructs',\n",
        "    'deduce', 'deduced', 'deduces', 'deducing',\n",
        "    'delegate', 'delegated', 'delegating', 'delegates',\n",
        "    'detect', 'detected', 'detecting', 'detects',\n",
        "    'diagnose', 'diagnosed', 'diagnosing', 'diagnoses',\n",
        "    'differentiate', 'differentiated', 'differentiating', 'differentiates',\n",
        "    'discriminate', 'discriminated', 'discriminating', 'discriminates',\n",
        "    'dissect', 'dissected', 'dissecting', 'dissects',\n",
        "    'distinguish', 'distinguished', 'distinguishing', 'distinguishes',\n",
        "    'document', 'documented', 'documenting', 'documents',\n",
        "\t\t'elaborate', 'elaborated', 'elaborates', 'elaborating',\n",
        "    'ensnare', 'ensnared', 'ensnaring', 'ensnares',\n",
        "    'explore', 'explored', 'exploring', 'explores',\n",
        "\t\t'factor', 'factored', 'factoring', 'factors',\n",
        "    'figure out', 'figures out', 'figured out', 'figuring out',\n",
        "    'file', 'filed', 'filing', 'files',\n",
        "    'function', 'functioned', 'functioning', 'functions',\n",
        "    'group', 'grouped', 'grouping', 'groups',\n",
        "    'infer', 'inferred', 'inferring', 'infers',\n",
        "    'inference', 'inferences', 'inferenced', 'inferencing',\n",
        "    'inspect', 'inspected', 'inspecting', 'inspects',\n",
        "    'integrate', 'integrated', 'integrating', 'integrates',\n",
        "\t\t'interpret', 'interpreted', 'interpreting', 'interprets',\n",
        "    'inventory', 'inventoried', 'inventorying', 'inventories',\n",
        "    'investigate', 'investigated', 'investigating', 'investigates',\n",
        "    'layout', 'layouts', 'layouted', 'layouting',\n",
        "    'mash', 'mashed', 'mashing', 'mashes',\n",
        "    'maximize', 'maximized', 'maximizing', 'maximizes',\n",
        "    'mind-map', 'mind-mapped', 'mind-mapping', 'mind-maps',\n",
        "    'minimize', 'minimized', 'minimizing', 'minimizes',\n",
        "    'motive', 'motived', 'motiving', 'motives',\n",
        "    'optimize', 'optimized', 'optimizing', 'optimizes',\n",
        "    'order', 'ordered', 'ordering', 'orders',\n",
        "\t\t'organize', 'organizes', 'organized', 'organizing',\n",
        "    'point out', 'point outs', 'point outed', 'point outing',\n",
        "\t\t'predict', 'predicted', 'predicting', 'predicts',\n",
        "    'proofread', 'proofreaded', 'proofreading', 'proofreads',\n",
        "    'query', 'queryed', 'querying', 'querys',\n",
        "    'question', 'questioned', 'questioning', 'questions',\n",
        "    'relationship', 'relationshiped', 'relationshiping', 'relationships',\n",
        "    'select', 'selected', 'selecting', 'selects',\n",
        "    'separate', 'separated', 'separating', 'separates',\n",
        "    'size up', 'size ups', 'size uped', 'size uping',\n",
        "    'structure', 'structured', 'structuring', 'structures',\n",
        "    'subdivide', 'subdivided', 'subdividing', 'subdivides',\n",
        "    'survey', 'surveyed', 'surveying', 'surveys',\n",
        "    'take part in', 'takes part in', 'took part in', 'taking part in',\n",
        "    'test for', 'tests for', 'tested for', 'testing for',\n",
        "    'theme', 'themed', 'theming', 'themes',\n",
        "    'train', 'trained', 'training', 'trains',\n",
        "    'transform', 'transformed', 'transforming', 'transforms',\n",
        "    'troubleshoot', 'troubleshooted', 'troubleshooting', 'troubleshoots'\n",
        "]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QTwIvFwHiD9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evaluative (Evaluation)\n",
        "\n",
        "bloom_evaluation = [\n",
        "    'advise', 'advised', 'advises', 'advising',\n",
        "    'agree', 'agreed', 'agrees', 'agreeing',\n",
        "    'appraise', 'appraised', 'appraises', 'appraising',\n",
        "    'argue', 'argued', 'argues', 'arguing',\n",
        "    'assess', 'assessed', 'assessing', 'assesses',\n",
        "    'authenticate', 'authenticated', 'authenticates', 'authenticating',\n",
        "    'award', 'awarded', 'awarding', 'awards',\n",
        "    'comment', 'commented', 'commenting', 'comments',\n",
        "    'conclude', 'concluded', 'concludes', 'concluding',\n",
        "    'counsel', 'counseled', 'counseling', 'counsels',\n",
        "    'criteria', 'criteriaed', 'criteriaing', 'criterias',\n",
        "    'criticize', 'criticized', 'criticizes', 'criticizing',\n",
        "    'critique', 'critiqued', 'critiques', 'critiquing',\n",
        "    'debate', 'debated', 'debates', 'debating',\n",
        "    'decide', 'decided', 'decides', 'deciding',\n",
        "    'deduct', 'deducted', 'deducting', 'deducts',\n",
        "    'defend', 'defended', 'defending', 'defends',\n",
        "\t\t'discuss', 'discussed', 'discussing', 'discusses',\n",
        "    'disprove', 'disproved', 'disproving', 'disproves',\n",
        "    'editorialize', 'editorialized', 'editorializes', 'editorializing',\n",
        "    'evaluate', 'evaluated', 'evaluating', 'evaluates',\n",
        "\t\t'generalize', 'generalized', 'generalizes', 'generalizing',\n",
        "    'grade', 'graded', 'grading', 'grades',\n",
        "    'hire', 'hired', 'hiring', 'hires',\n",
        "    'importance', 'importanced', 'importancing', 'importances',\n",
        "    'influence', 'influenced', 'influencing', 'influences',\n",
        "    'judge', 'judged', 'judging', 'judges',\n",
        "    'justify', 'justified', 'justifying', 'justifies',\n",
        "    'mark', 'marked', 'marking', 'marks',\n",
        "    'measure', 'measured', 'measuring', 'measures',\n",
        "    'moderate', 'moderated', 'moderating', 'moderates',\n",
        "    'opinion', 'opinioned', 'opinioning', 'opinions',\n",
        "    'perceive', 'perceived', 'perceiving', 'perceives',\n",
        "    'post', 'posted', 'posting', 'posts',\n",
        "    'prescribe', 'prescribed', 'prescribing', 'prescribes',\n",
        "    'preserve', 'preserved', 'preserving', 'preserves',\n",
        "    'prioritize', 'prioritized', 'prioritizing', 'prioritizes',\n",
        "    'prove', 'proved', 'proving', 'proves',\n",
        "    'rank', 'ranked', 'ranking', 'ranks',\n",
        "    'rate', 'rated', 'rating', 'rates',\n",
        "    'recommend', 'recommended', 'recommending', 'recommends',\n",
        "    'reconcile', 'reconciled', 'reconciling', 'reconciles',\n",
        "    'reflect', 'reflected', 'reflecting', 'reflects',\n",
        "    'release', 'released', 'releasing', 'releases',\n",
        "    'resolve', 'resolved', 'resolving', 'resolves',\n",
        "    'rule on', 'ruled on', 'ruling on', 'rules on',\n",
        "    'score', 'scored', 'scoring', 'scores',\n",
        "    'support', 'supported', 'supporting', 'supports',\n",
        "    'test', 'tested', 'testing', 'tests',\n",
        "    'uphold', 'upholded', 'upholding', 'upholds',\n",
        "    'validate', 'validated', 'validating', 'validates',\n",
        "    'value', 'valued', 'valuing', 'values',\n",
        "    'verify', 'verified', 'verifying', 'verifies',\n",
        "    'weigh', 'weighed', 'weighing', 'weighs'\n",
        "]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EoKNa2bQiF1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Synthetic (Creation)\n",
        "\n",
        "bloom_creation = [\n",
        "    'abstract', 'abstracted', 'abstracting', 'abstracts',\n",
        "    'adapt', 'adapted', 'adapting', 'adapts',\n",
        "    'animate', 'animated', 'animating', 'animates',\n",
        "    'anticipate', 'anticipated', 'anticipating', 'anticipates',\n",
        "    'arbitrate', 'arbitrated', 'arbitrating', 'arbitrates',\n",
        "    'arrange', 'arranged', 'arranging', 'arranges',\n",
        "    'assemble', 'assembled', 'assembling', 'assembles',\n",
        "    'blog', 'blogged', 'blogging', 'blogs',\n",
        "    'brief', 'briefed', 'briefing', 'briefs',\n",
        "    'budget', 'budgeted', 'budgeting', 'budgets',\n",
        "    'build', 'built', 'building', 'builds',\n",
        "    'code', 'coded', 'coding', 'codes',\n",
        "    'collaborate', 'collaborated', 'collaborating', 'collaborates',\n",
        "    'collect', 'collected', 'collecting', 'collects',\n",
        "    'combine', 'combined', 'combining', 'combines',\n",
        "    'compile', 'compiled', 'compiling', 'compiles',\n",
        "    'compose', 'composed', 'composing', 'composes',\n",
        "    'construct', 'constructed', 'constructing', 'constructs',\n",
        "    'cope', 'coped', 'coping', 'copes',\n",
        "    'correspond', 'corresponded', 'corresponding', 'corresponds',\n",
        "    'create', 'created', 'creating', 'creates',\n",
        "    'cultivate', 'cultivated', 'cultivating', 'cultivates',\n",
        "    'debug', 'debugged', 'debugging', 'debugs',\n",
        "    'delete', 'deleted', 'deleting', 'deletes',\n",
        "    'depict', 'depicted', 'depicting', 'depicts',\n",
        "    'design', 'designed', 'designing', 'designs',\n",
        "    'develop', 'developed', 'developing', 'develops',\n",
        "    'devise', 'devised', 'devising', 'devises',\n",
        "    'dictate', 'dictated', 'dictating', 'dictates',\n",
        "    'direct', 'directed', 'directing', 'directs',\n",
        "    'enhance', 'enhanced', 'enhancing', 'enhances',\n",
        "    'facilitate', 'facilitated', 'facilitating', 'facilitates',\n",
        "    'film', 'filmed', 'filming', 'films',\n",
        "    'format', 'formatted', 'formatting', 'formats',\n",
        "    'formulate', 'formulated', 'formulating', 'formulates',\n",
        "    'generate', 'generated', 'generating', 'generates',\n",
        "    'happen', 'happened', 'happening', 'happens',\n",
        "    'hypothesize', 'hypothesized', 'hypothesizing', 'hypothesizes',\n",
        "    'imagine', 'imagined', 'imagining', 'imagines',\n",
        "    'import', 'imported', 'importing', 'imports',\n",
        "    'improve', 'improved', 'improving', 'improves',\n",
        "    'incorporate', 'incorporated', 'incorporating', 'incorporates',\n",
        "    'interface', 'interfaced', 'interfacing', 'interfaces',\n",
        "    'invent', 'invented', 'inventing', 'invents',\n",
        "    'join', 'joined', 'joining', 'joins',\n",
        "    'lead', 'led', 'leading', 'leads',\n",
        "    'lecture', 'lectured', 'lecturing', 'lectures',\n",
        "    'make up', 'made up', 'making up', 'makes up',\n",
        "    'mix', 'mixed', 'mixing', 'mixes',\n",
        "    'model', 'modeled', 'modelling', 'models',\n",
        "    'negotiate', 'negotiated', 'negotiating', 'negotiates',\n",
        "    'network', 'networked', 'networking', 'networks',\n",
        "    'original', 'originals',\n",
        "    'originate', 'originated', 'originating', 'originates',\n",
        "    'overhaul', 'overhauled', 'overhauling', 'overhauls',\n",
        "    'plan', 'planned', 'planning', 'plans',\n",
        "    'podcast', 'podcasted', 'podcasting', 'podcasts',\n",
        "    'portray', 'portrayed', 'portraying', 'portrays',\n",
        "    'produce', 'produced', 'producing', 'produces',\n",
        "    'program', 'programmed', 'programming', 'programs',\n",
        "    'propose', 'proposed', 'proposing', 'proposes',\n",
        "    'rearrange', 'rearranged', 'rearranging', 'rearranges',\n",
        "    'reconstruct', 'reconstructed', 'reconstructing', 'reconstructs',\n",
        "    'revise', 'revised', 'revising', 'revises',\n",
        "    'rewrite', 'rewritten', 'rewriting', 'rewrites',\n",
        "    'role play', 'role played', 'role playing', 'role plays',\n",
        "    'role-playing', 'role-played', 'role-plays',\n",
        "    'solution', 'solutions', 'solutioned', 'solutioning',\n",
        "    'specify', 'specified', 'specifying', 'specifies',\n",
        "    'suppose', 'supposed', 'supposing', 'supposes',\n",
        "    'teach', 'taught', 'teaching', 'teaches',\n",
        "    'theory', 'theorized', 'theorizing', 'theories',\n",
        "    'unify', 'unified', 'unifying', 'unifies',\n",
        "    'wiki building', 'wiki built', 'wiki builds',\n",
        "    'write', 'wrote', 'writing', 'writes'\n",
        "]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LBmzcKRViKVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Checking for Duplicates\n",
        "\n",
        "item_occurrences = {}\n",
        "\n",
        "# List of all lists for easy iteration\n",
        "all_lists = {\n",
        "    'bloom_knowledge': bloom_knowledge,\n",
        "    'bloom_understand': bloom_understand,\n",
        "    'bloom_application': bloom_application,\n",
        "    'bloom_analysis': bloom_analysis,\n",
        "    'bloom_evaluation': bloom_evaluation,\n",
        "    'bloom_creation': bloom_creation\n",
        "}\n",
        "\n",
        "# Iterating through each list and update the dictionary\n",
        "for list_name, items in all_lists.items():\n",
        "    for item in items:\n",
        "        if item not in item_occurrences:\n",
        "            item_occurrences[item] = []\n",
        "        item_occurrences[item].append(list_name)\n",
        "\n",
        "# Filtering items that exist in more than one list\n",
        "common_items = {item: lists for item, lists in item_occurrences.items() if len(lists) > 1}\n",
        "\n",
        "# Printing the results\n",
        "for item, lists in common_items.items():\n",
        "    print(f\"{item}' exists in: {', '.join(lists)}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GAKX1jSniOVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "F_j3FrB4iSoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Points for each list\n",
        "points = {\n",
        "    'bloom_knowledge': 10,\n",
        "    'bloom_understand': 20,\n",
        "    'bloom_application': 20,\n",
        "    'bloom_analysis': 25,\n",
        "    'bloom_evaluation': 35,\n",
        "    'bloom_creation': 40\n",
        "}\n",
        "\n",
        "# Pre-compile regular expressions for each keyword and store them in a dictionary\n",
        "compiled_keywords = {key: [re.compile(r'\\b' + re.escape(kw.lower()) + r'\\b') for kw in globals()[key]]\n",
        "                     for key in points.keys()}\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('Data_Structure.csv')\n",
        "dg = pd.read_csv('Introduction_to_Computers_and_Research.csv')\n",
        "dh = pd.read_csv('Irrelevant_Questions.csv')\n",
        "\n",
        "# Function to calculate score\n",
        "def calculate_score(question, compiled_keywords, points):\n",
        "    score = 0\n",
        "    lower_question = question.lower()\n",
        "    for key, regex_list in compiled_keywords.items():\n",
        "        for regex in regex_list:\n",
        "            if regex.search(lower_question):\n",
        "                score += points[key]\n",
        "                break\n",
        "    return score\n",
        "\n",
        "# Applying the function to each question\n",
        "df['Updated Score'] = df['Questions'].apply(lambda x: calculate_score(x, compiled_keywords, points))\n",
        "dg['Updated Score'] = dg['Questions'].apply(lambda x: calculate_score(x, compiled_keywords, points))\n",
        "dh['Updated Score'] = dh['Questions'].apply(lambda x: calculate_score(x, compiled_keywords, points))\n",
        "\n",
        "# Saving the updated DataFrame to a new CSV file\n",
        "df.to_csv('updated_Data_Structure.csv', index=False)\n",
        "dg.to_csv('updated_Introduction_to_Computers_and_Research.csv', index=False)\n",
        "dh.to_csv('updated_Irrelevant_Questions.csv', index=False)"
      ],
      "metadata": {
        "id": "gdNm0ZOriSHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Verifying Evaluation for a Single Question\n",
        "\n",
        "import re\n",
        "\n",
        "question = \"Can you discuss the process of deleting a node from a binary search tree while maintaining its properties?\"\n",
        "\n",
        "# Function to identify the keyword in the question\n",
        "def find_keyword_in_question(question, keywords):\n",
        "    lower_question = question.lower()\n",
        "    # Using a regular expression to match whole words only\n",
        "    matched_keywords = [keyword for keyword in keywords if re.findall(r'\\b' + re.escape(keyword.lower()) + r'\\b', lower_question)]\n",
        "    return matched_keywords\n",
        "\n",
        "# Finding the keyword from the list in the question\n",
        "matched_keywords = find_keyword_in_question(question, bloom_knowledge)\n",
        "matched_keywords2 = find_keyword_in_question(question, bloom_understand)\n",
        "matched_keywords3 = find_keyword_in_question(question, bloom_application)\n",
        "matched_keywords4 = find_keyword_in_question(question, bloom_analysis)\n",
        "matched_keywords5 = find_keyword_in_question(question, bloom_evaluation)\n",
        "matched_keywords6 = find_keyword_in_question(question, bloom_creation)\n",
        "\n",
        "# Printing the matched keywords\n",
        "print(\"Matched Knowledge Keywords:\", matched_keywords)\n",
        "print(\"Matched Understanding Keywords:\", matched_keywords2)\n",
        "print(\"Matched Application Keywords:\", matched_keywords3)\n",
        "print(\"Matched Analysis Keywords:\", matched_keywords4)\n",
        "print(\"Matched Evaluation Keywords:\", matched_keywords5)\n",
        "print(\"Matched Creation Keywords:\", matched_keywords6)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k0MKNrP-iYl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSV Generation"
      ],
      "metadata": {
        "id": "4nieAwNgik6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Padding shorter lists to match the length of the longest list\n",
        "lists = [bloom_knowledge, bloom_understand, bloom_application, bloom_analysis, bloom_evaluation, bloom_creation]\n",
        "max_length = max(len(lst) for lst in lists)\n",
        "for lst in lists:\n",
        "    lst.extend([''] * (max_length - len(lst)))\n",
        "\n",
        "# Writing to CSV\n",
        "with open('bloom_taxonomy.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    # Writing the header (optional)\n",
        "    writer.writerow(['Remember', 'Understand', 'Apply', 'Analyze', 'Evaluate', 'Create'])\n",
        "    # Writing the data\n",
        "    for i in range(max_length):\n",
        "        writer.writerow([lst[i] for lst in lists])\n",
        "\n",
        "print(\"CSV file created successfully.\")"
      ],
      "metadata": {
        "id": "SIIDkqGKioCb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}